<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Meta Information -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Yue Zhao" />
    <meta name="description" content="Course website of CSCI 699: Adversarial and Trustworthy Foundation Models (USC)" />
    <meta name="keywords" content="foundation models, LLM security, adversarial machine learning, trustworthiness, CSCI699, USC, Yue Zhao" />

    <!-- Title and Favicon -->
    <title>CSCI 699 Adversarial and Trustworthy Foundation Models (Spring 2026)</title>
    <link rel="icon" type="image/x-icon" href="images/logo2.ico" />

    <!-- Stylesheets -->
    <link rel="stylesheet" href="https://unpkg.com/bootstrap@5.3.0/dist/css/bootstrap.min.css" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" />
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@700&display=swap" rel="stylesheet" />

    <!-- Scripts -->
    <script src="https://unpkg.com/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>

    <style>
      body {
        font-family: "Roboto", "-apple-system", "BlinkMacSystemFont", "Segoe UI", "Helvetica Neue", "Arial", "Noto Sans",
          "sans-serif", "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
      }
      h1, h2, h3 {
        text-align: center;
      }
      .university-color {
        color: #990000;
      }
      .link-list a {
        margin-right: 5px;
      }

      /* Staff Container Styles */
      .staff-container {
        display: flex;
        justify-content: center;
        align-items: stretch;
        flex-wrap: wrap;
        margin: 20px;
      }
      .staff-member {
        width: 360px;
        max-width: 95%;
        text-align: center;
        margin: 15px;
        box-sizing: border-box;
      }
      .staff-member img {
        width: 70%;
        max-width: 160px;
        height: auto;
        border-radius: 50%;
        margin-bottom: 10px;
      }
      .staff-member h2, .staff-member p {
        margin: 5px 0;
      }

      /* Responsive Styles */
      @media only screen and (max-width: 1024px) {
        .staff-member img {
          width: 65%;
          max-width: 150px;
        }
      }
      @media only screen and (max-width: 768px) {
        .staff-member {
          width: 100%;
          margin: 15px 0;
        }
        .staff-member img {
          width: 60%;
          max-width: 140px;
        }
      }
    </style>
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark mb-4">
      <div class="container">
        <a class="navbar-brand" href="#">CSCI 699 Adversarial and Trustworthy Foundation Models</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
          aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav custom-spacing">
            <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
            <li class="nav-item"><a class="nav-link" href="schedule.html">Course Schedule</a></li>
            <!-- 建议你把 syllabus 放到仓库里，例如 syllabus.html / syllabus.pdf / syllabus.docx -->
<!--            <li class="nav-item"><a class="nav-link" href="syllabus.html">Syllabus</a></li>-->
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container">
      <h2>
        CSCI 699: Adversarial and Trustworthy Foundation Models (Spring 2026)
        <span style="color: #888; font-size: 0.95em;">
<!--          <a href="mailto:yue.z@usc.edu" style="color: #888; text-decoration: none;">yue.z@usc.edu</a>-->
        </span>
      </h2>

      <div style="text-align: center;">
        <img width="420" src="images/usc-banner.png" alt="USC banner" />
      </div>

      <div class="col" style="margin-top: 3%; text-align: left;">
        <p>
          <strong class="university-color">To Students</strong>:
          This website is under construction; please check back frequently. Course logistics may change.
        </p>

        <p>
          <strong class="university-color">Catalogue Description</strong>:
          Security, privacy, and trust in large language, vision-language, and agent models; adversarial attacks and defenses.
        </p>

        <p>
          <strong class="university-color">Course Description</strong>:
          This advanced graduate seminar examines security, privacy, and trust in large-scale AI systems, including large language
          models (LLMs), vision-language models (VLMs), and autonomous agents. The course integrates theoretical foundations with
          recent research on adversarial attacks and defenses, robustness evaluation, alignment, transparency, and trustworthy
          deployment of foundation models.
        </p>

        <p>
          <strong class="university-color">Recommended Preparation</strong>:
          Deep learning/machine learning knowledge on the level of CSCI 566 and CSCI 567 (not a prerequisite though); familiarity
          with Python and modern AI frameworks (e.g., PyTorch). Prior exposure to large-scale ML, trustworthy AI, or security topics
          is helpful but not required.
        </p>

        <p><strong class="university-color">Basic logistics</strong>:</p>
        <ul>
          <li><strong>Course:</strong> CSCI 699 — Adversarial and Trustworthy Foundation Models</li>
          <li><strong>Units:</strong> 4.0</li>
          <li><strong>Section:</strong> 30335</li>
          <li><strong>Time:</strong> Wednesday, 2:00–5:20 PM</li>
          <li><strong>Location:</strong> DMC 150</li>
          <li><strong>Instructor:</strong> <a href="https://viterbi-web.usc.edu/~yzhao010/" target="_blank">Yue Zhao</a></li>
          <li><strong>Office Hours:</strong> Immediately after class, in the same room.</li>
          <li><strong>Discussion:</strong>
              <a href="https://piazza.com/class/mk8owhcdfmw4nd#" target="_blank">Piazza</a>
            </li>
<!--          <li><strong>Contact:</strong> <a href="mailto:yue.z@usc.edu">yue.z@usc.edu</a></li>-->
<!--          <li><strong>Teaching Assistant:</strong> None.</li>-->
        </ul>

        <p>
          <strong class="university-color">Learning Objectives</strong>:
          Students will learn to evaluate security, privacy, and robustness properties of foundation-model systems; analyze threat
          models and attack vectors; design experiments and metrics; assess defenses and alignment methods; and complete a research-grade
          project connected to adversarial and trustworthy AI.
        </p>

        <p>
          <strong class="university-color">Assessment</strong>:
          Paper Presentations (30%), Homework/Experimental Assignments (10%), Semester Research Project (50%), Participation (10%).
        </p>

        <p>
          <strong class="university-color">Course Format</strong>:
          Weekly seminar with student-led paper presentations, in-class discussion, and a semester-long project. Materials and submissions
          will be managed via Brightspace and related tooling (e.g., Gradescope/GitHub Classroom when applicable).
        </p>

<!--        <p>-->
<!--          <strong class="university-color">Required Readings (selected)</strong>:-->
<!--          Joseph et al., <em>Adversarial Machine Learning</em> (2019); Huang et al., TrustLLM (arXiv 2401.05561); Tang et al., StealthRank-->
<!--          (arXiv 2504.05804); Liu et al., USENIX Security prompt injection benchmarking; Goodfellow et al., adversarial examples (arXiv 1412.6572).-->
<!--        </p>-->
      </div>

<!--      <hr />-->

<!--      <div class="staff-container">-->
<!--        &lt;!&ndash; Instructor &ndash;&gt;-->
<!--        <div class="staff-member">-->
<!--          <img src="images/300.png" alt="Yue Zhao" />-->
<!--          <h3>Instructor</h3>-->
<!--          <p><a href="https://viterbi-web.usc.edu/~yzhao010/" target="_blank" style="color: blue; text-decoration: underline;">Yue Zhao</a></p>-->
<!--          <p>Office Hours: immediately after class, in the same room</p>-->
<!--&lt;!&ndash;          <p>Contact: <a href="mailto:yue.z@usc.edu">yue.z@usc.edu</a></p>&ndash;&gt;-->
<!--        </div>-->
<!--      </div>-->
    </div>

    <footer style="background-color: #f9f9f9; padding: 20px; text-align: center; border-top: 2px solid #e5e5e5; margin-top: 50px;">
      <p style="font-family: 'Oswald', sans-serif; font-size: 15px; color: #555;">© Copyright 2026 University of Southern California.</p>
      <p style="font-family: 'Oswald', sans-serif; font-size: 15px; color: #555;">
        Written by Yue Zhao and ChatGPT. <a href="https://github.com/USC-ASAP/CICS566-S24" target="_blank" style="color: #888; text-decoration: none;">Reuse our code</a>.
      </p>
    </footer>
  </body>
</html>
